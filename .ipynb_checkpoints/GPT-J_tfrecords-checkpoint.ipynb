{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvAEHzZ5c3_1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd7iKbfRPNXs"
   },
   "source": [
    "# GPT2 with Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugqA8sTyorE7"
   },
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VA0fsB0kkO3P"
   },
   "outputs": [],
   "source": [
    "data = np.load('data/forex/all_forex_data_ffill_test.csv.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 0 0\n",
      "62838 121 0\n",
      "128952 62959 0\n",
      "254957 191911 0\n",
      "285701 446868 0\n",
      "279026 732569 0\n",
      "264136 1011595 0\n",
      "280411 1275731 0\n",
      "330754 1556142 0\n",
      "351071 1886896 0\n",
      "351500 2237967 0\n",
      "355475 2589467 0\n",
      "370878 2944942 0\n",
      "370120 3315820 0\n",
      "365190 3685940 0\n",
      "371187 4051130 0\n",
      "371005 4422317 0\n",
      "368436 4793322 0\n",
      "369457 5161758 0\n",
      "371998 5531215 0\n",
      "371875 5903213 0\n",
      "38908 0 1\n",
      "306992 38908 1\n",
      "300099 345900 1\n",
      "287891 645999 1\n",
      "271410 933890 1\n",
      "293648 1205300 1\n",
      "296922 1498948 1\n",
      "273114 1795870 1\n",
      "307097 2068984 1\n",
      "313629 2376081 1\n",
      "319110 2689710 1\n",
      "143167 0 2\n",
      "230767 143167 2\n",
      "213000 373934 2\n",
      "316351 586934 2\n",
      "328426 903285 2\n",
      "315635 1231711 2\n",
      "307176 1547346 2\n",
      "299782 1854522 2\n",
      "347355 2154304 2\n",
      "355880 2501659 2\n",
      "352320 2857539 2\n",
      "358369 3209859 2\n",
      "372161 3568228 2\n",
      "370611 3940389 2\n",
      "366477 4311000 2\n",
      "372210 4677477 2\n",
      "372679 5049687 2\n",
      "371635 5422366 2\n",
      "372607 5794001 2\n",
      "372530 6166608 2\n",
      "372335 6539138 2\n",
      "132267 0 3\n",
      "203038 132267 3\n",
      "194701 335305 3\n",
      "296418 530006 3\n",
      "314580 826424 3\n",
      "311286 1141004 3\n",
      "308909 1452290 3\n",
      "306750 1761199 3\n",
      "332167 2067949 3\n",
      "354178 2400116 3\n",
      "348663 2754294 3\n",
      "349323 3102957 3\n",
      "371796 3452280 3\n",
      "370762 3824076 3\n",
      "368916 4194838 3\n",
      "372231 4563754 3\n",
      "372480 4935985 3\n",
      "371204 5308465 3\n",
      "372261 5679669 3\n",
      "372396 6051930 3\n",
      "373057 6424326 3\n",
      "40855 0 4\n",
      "331649 40855 4\n",
      "325049 372504 4\n",
      "314774 697553 4\n",
      "318873 1012327 4\n",
      "335257 1331200 4\n",
      "341629 1666457 4\n",
      "330380 2008086 4\n",
      "348607 2338466 4\n",
      "341395 2687073 4\n",
      "340022 3028468 4\n",
      "89140 0 5\n",
      "243843 89140 5\n",
      "265516 332983 5\n",
      "293747 598499 5\n",
      "314089 892246 5\n",
      "314942 1206335 5\n",
      "325762 1521277 5\n",
      "370928 1847039 5\n",
      "369180 2217967 5\n",
      "367530 2587147 5\n",
      "370151 2954677 5\n",
      "370255 3324828 5\n",
      "367888 3695083 5\n",
      "369917 4062971 5\n",
      "372016 4432888 5\n",
      "371402 4804904 5\n",
      "29008 0 6\n",
      "277850 29008 6\n",
      "251514 306858 6\n",
      "229617 558372 6\n",
      "233233 787989 6\n",
      "281125 1021222 6\n",
      "282913 1302347 6\n",
      "222026 1585260 6\n",
      "310381 1807286 6\n",
      "308354 2117667 6\n",
      "334261 2426021 6\n",
      "39501 0 7\n",
      "326532 39501 7\n",
      "315031 366033 7\n",
      "304215 681064 7\n",
      "302247 985279 7\n",
      "333325 1287526 7\n",
      "339940 1620851 7\n",
      "317200 1960791 7\n",
      "345798 2277991 7\n",
      "293164 2623789 7\n",
      "311216 2916953 7\n",
      "9 0 8\n",
      "99435 9 8\n",
      "127353 99444 8\n",
      "248005 226797 8\n",
      "244743 474802 8\n",
      "240039 719545 8\n",
      "235208 959584 8\n",
      "246689 1194792 8\n",
      "276953 1441481 8\n",
      "313683 1718434 8\n",
      "325765 2032117 8\n",
      "321834 2357882 8\n",
      "367869 2679716 8\n",
      "364836 3047585 8\n",
      "358110 3412421 8\n",
      "368537 3770531 8\n",
      "369715 4139068 8\n",
      "366222 4508783 8\n",
      "367942 4875005 8\n",
      "372305 5242947 8\n",
      "372293 5615252 8\n",
      "151350 0 9\n",
      "252065 151350 9\n",
      "234797 403415 9\n",
      "330304 638212 9\n",
      "317510 968516 9\n",
      "315026 1286026 9\n",
      "308133 1601052 9\n",
      "296611 1909185 9\n",
      "330894 2205796 9\n",
      "350852 2536690 9\n",
      "345932 2887542 9\n",
      "333896 3233474 9\n",
      "371726 3567370 9\n",
      "370700 3939096 9\n",
      "366487 4309796 9\n",
      "370863 4676283 9\n",
      "371548 5047146 9\n",
      "369892 5418694 9\n",
      "370264 5788586 9\n",
      "371141 6158850 9\n",
      "370406 6529991 9\n",
      "48538 0 10\n",
      "363240 48538 10\n",
      "355795 411778 10\n",
      "346851 767573 10\n",
      "326715 1114424 10\n",
      "346182 1441139 10\n",
      "365194 1787321 10\n",
      "361300 2152515 10\n",
      "365735 2513815 10\n",
      "364086 2879550 10\n",
      "362346 3243636 10\n",
      "118703 0 11\n",
      "362388 118703 11\n",
      "363475 481091 11\n",
      "369750 844566 11\n",
      "372162 1214316 11\n",
      "370672 1586478 11\n",
      "368929 1957150 11\n",
      "370773 2326079 11\n",
      "370268 2696852 11\n",
      "369574 3067120 11\n",
      "370113 3436694 11\n",
      "371002 3806807 11\n",
      "366321 4177809 11\n",
      "30403 0 12\n",
      "49209 30403 12\n",
      "108102 79612 12\n",
      "139717 187714 12\n",
      "165345 327431 12\n",
      "147921 492776 12\n",
      "124256 640697 12\n",
      "139675 764953 12\n",
      "191791 904628 12\n",
      "227162 1096419 12\n",
      "206285 1323581 12\n",
      "307527 1529866 12\n",
      "326879 1837393 12\n",
      "48417 0 13\n",
      "347537 48417 13\n",
      "359830 395954 13\n",
      "351515 755784 13\n",
      "336088 1107299 13\n",
      "351498 1443387 13\n",
      "352010 1794885 13\n",
      "354150 2146895 13\n",
      "360260 2501045 13\n",
      "332532 2861305 13\n",
      "330125 3193837 13\n",
      "131241 0 14\n",
      "244200 131241 14\n",
      "238609 375441 14\n",
      "330526 614050 14\n",
      "321941 944576 14\n",
      "312962 1266517 14\n",
      "315950 1579479 14\n",
      "322788 1895429 14\n",
      "348226 2218217 14\n",
      "343456 2566443 14\n",
      "328836 2909899 14\n",
      "300286 3238735 14\n",
      "365686 3539021 14\n",
      "370808 3904707 14\n",
      "366741 4275515 14\n",
      "371891 4642256 14\n",
      "372417 5014147 14\n",
      "371298 5386564 14\n",
      "371800 5757862 14\n",
      "372585 6129662 14\n",
      "372200 6502247 14\n",
      "34327 0 15\n",
      "267146 34327 15\n",
      "333034 301473 15\n",
      "326614 634507 15\n",
      "320776 961121 15\n",
      "335631 1281897 15\n",
      "350131 1617528 15\n",
      "333850 1967659 15\n",
      "351576 2301509 15\n",
      "362206 2653085 15\n",
      "360288 3015291 15\n",
      "104575 0 16\n",
      "361285 104575 16\n",
      "363984 465860 16\n",
      "366007 829844 16\n",
      "371358 1195851 16\n",
      "367308 1567209 16\n",
      "361639 1934517 16\n",
      "367459 2296156 16\n",
      "367734 2663615 16\n",
      "368214 3031349 16\n",
      "370218 3399563 16\n",
      "371262 3769781 16\n",
      "366999 4141043 16\n",
      "44688 0 17\n",
      "353000 44688 17\n",
      "361616 397688 17\n",
      "358550 759304 17\n",
      "340964 1117854 17\n",
      "353858 1458818 17\n",
      "363119 1812676 17\n",
      "355892 2175795 17\n",
      "366399 2531687 17\n",
      "371080 2898086 17\n",
      "368371 3269166 17\n",
      "107061 0 18\n",
      "361297 107061 18\n",
      "365270 468358 18\n",
      "361733 833628 18\n",
      "371195 1195361 18\n",
      "368923 1566556 18\n",
      "367745 1935479 18\n",
      "370933 2303224 18\n",
      "372312 2674157 18\n",
      "371451 3046469 18\n",
      "372094 3417920 18\n",
      "369277 3790014 18\n",
      "368473 4159291 18\n",
      "62833 0 19\n",
      "188477 62833 19\n",
      "208234 251310 19\n",
      "257315 459544 19\n",
      "317496 716859 19\n",
      "314497 1034355 19\n",
      "314413 1348852 19\n",
      "349725 1663265 19\n",
      "360764 2012990 19\n",
      "350044 2373754 19\n",
      "345062 2723798 19\n",
      "370612 3068860 19\n",
      "366442 3439472 19\n",
      "29010 0 20\n",
      "247623 29010 20\n",
      "312882 276633 20\n",
      "296997 589515 20\n",
      "299684 886512 20\n",
      "325916 1186196 20\n",
      "333387 1512112 20\n",
      "323487 1845499 20\n",
      "331581 2168986 20\n",
      "364358 2500567 20\n",
      "304821 2864925 20\n",
      "34126 0 21\n",
      "264297 34126 21\n",
      "319633 298423 21\n",
      "316558 618056 21\n",
      "317147 934614 21\n",
      "330270 1251761 21\n",
      "338838 1582031 21\n",
      "315906 1920869 21\n",
      "320076 2236775 21\n",
      "364313 2556851 21\n",
      "355409 2921164 21\n",
      "41143 0 22\n",
      "318466 41143 22\n",
      "333544 359609 22\n",
      "320814 693153 22\n",
      "308208 1013967 22\n",
      "326253 1322175 22\n",
      "317338 1648428 22\n",
      "271477 1965766 22\n",
      "318142 2237243 22\n",
      "325027 2555385 22\n",
      "342692 2880412 22\n",
      "204903 0 23\n",
      "298572 204903 23\n",
      "332009 503475 23\n",
      "347324 835484 23\n",
      "342532 1182808 23\n",
      "335480 1525340 23\n",
      "333551 1860820 23\n",
      "338733 2194371 23\n",
      "322329 2533104 23\n",
      "345881 2855433 23\n",
      "334890 3201314 23\n",
      "351480 3536204 23\n",
      "276109 0 24\n",
      "346196 276109 24\n",
      "352266 622305 24\n",
      "354797 974571 24\n",
      "355160 1329368 24\n",
      "351606 1684528 24\n",
      "351666 2036134 24\n",
      "353415 2387800 24\n",
      "352360 2741215 24\n",
      "353778 3093575 24\n",
      "352688 3447353 24\n",
      "354351 3800041 24\n"
     ]
    }
   ],
   "source": [
    "directory = '../FX-1-Minute-Data/output'\n",
    "folders = [x[0].split('\\\\')[-1] for x in os.walk(directory)][1:]\n",
    "data = []\n",
    "for folder in folders:\n",
    "    zip_files = [f for f in listdir(f'{directory}/{folder}') if f.endswith('.zip') and '2021' not in f and 'USD' in f]\n",
    "\n",
    "    dfs = pd.DataFrame()\n",
    "    for file in zip_files:\n",
    "        zip_file = ZipFile(f'{directory}/{folder}/{file}')\n",
    "        df = pd.read_csv(zip_file.open(file[:-4]+'.csv'), names=['datetime', 'open', 'high', 'low', 'close', 'volume'], sep=';')\n",
    "        df['datetime'] = df['datetime'].apply(lambda x: f'{x[:4]}-{x[4:6]}-{x[6:8]}T{x[9:11]}:{x[11:13]}:{x[13:15]}')\n",
    "        df['day'] = df['datetime'].apply(lambda x: x.split('T')[0])\n",
    "        df['minutes'] = df['datetime'].apply(lambda x: int(x.split('T')[1][:2])*60+int(x.split('T')[1][3:5]))\n",
    "        print(len(df), len(dfs), len(data))\n",
    "    \n",
    "        df['file'] = file\n",
    "        dfs = dfs.append(df)\n",
    "    if dfs.shape[0] > 0:\n",
    "        data.append(dfs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA_1min.txt\n",
      "1178178 0\n",
      "BAT_1min.txt\n",
      "500581 1\n",
      "BCH_1min.txt\n",
      "1846720 2\n",
      "BNT_1min.txt\n",
      "1465424 3\n",
      "BSV_1min.txt\n",
      "1146548 4\n",
      "BTC_1min.txt\n",
      "3554967 5\n",
      "BTG_1min.txt\n",
      "1578585 6\n",
      "CVC_1min.txt\n",
      "280251 7\n",
      "DAI_1min.txt\n",
      "671067 8\n",
      "DASH_1min.txt\n",
      "1863195 9\n",
      "DCR_1min.txt\n",
      "162446 10\n",
      "DOGE_1min.txt\n",
      "1572341 11\n",
      "EOS_1min.txt\n",
      "2088508 12\n",
      "ETC_1min.txt\n",
      "2120606 13\n",
      "ETH-BTC_1min.txt\n",
      "2129947 14\n",
      "ETH_1min.txt\n",
      "2240474 15\n",
      "FUN_1min.txt\n",
      "133190 16\n",
      "HT_1min.txt\n",
      "34993 17\n",
      "ICX_1min.txt\n",
      "931845 18\n",
      "IOST_1min.txt\n",
      "806987 19\n",
      "KNC_1min.txt\n",
      "658569 20\n",
      "LINK_1min.txt\n",
      "1027417 21\n",
      "LRC_1min.txt\n",
      "410189 22\n",
      "LSK_1min.txt\n",
      "872413 23\n",
      "LTC_1min.txt\n",
      "2280868 24\n",
      "MAID_1min.txt\n",
      "1672742 25\n",
      "MANA_1min.txt\n",
      "380961 26\n",
      "MKR_1min.txt\n",
      "583169 27\n",
      "NEO_1min.txt\n",
      "1719494 28\n",
      "OMG_1min.txt\n",
      "1587057 29\n",
      "ONT_1min.txt\n",
      "950428 30\n",
      "PAX_1min.txt\n",
      "151895 31\n",
      "QTUM_1min.txt\n",
      "1022029 32\n",
      "REP_1min.txt\n",
      "1255607 33\n",
      "SC_1min.txt\n",
      "224033 34\n",
      "SNT_1min.txt\n",
      "117930 35\n",
      "TRX_1min.txt\n",
      "1605460 36\n",
      "UST_1min.txt\n",
      "864117 37\n",
      "UTK_1min.txt\n",
      "308697 38\n",
      "VET_1min.txt\n",
      "250213 39\n",
      "WAVES_1min.txt\n",
      "148002 40\n",
      "XEM_1min.txt\n",
      "1575953 41\n",
      "XLM_1min.txt\n",
      "1491612 42\n",
      "XMR_1min.txt\n",
      "1949499 43\n",
      "XRP_1min.txt\n",
      "2187569 44\n",
      "XTZ_1min.txt\n",
      "1967156 45\n",
      "XVG_1min.txt\n",
      "865200 46\n",
      "ZEC_1min.txt\n",
      "2006366 47\n",
      "ZIL_1min.txt\n",
      "913905 48\n",
      "ZRX_1min.txt\n",
      "1894998 49\n"
     ]
    }
   ],
   "source": [
    "zf = ZipFile(f'data/firstratedata/crypto-active_1min_1nfzd.zip') \n",
    "data_files = zf.filelist\n",
    "data = []\n",
    "for file in data_files:\n",
    "    if file.filename.startswith('USDC') or file.filename.startswith('USDT') or file.filename.startswith('BTC-EUR'):\n",
    "        continue\n",
    "    print(file.filename)\n",
    "    df = pd.read_csv(zf.open(file), names=['datetime', 'Open', 'High', 'Low', 'close', 'Volume'])\n",
    "#     df['datetime'] = df['datetime'].apply(lambda x: f'{x[:4]}-{x[4:6]}-{x[6:8]}T{x[9:11]}:{x[11:13]}:{x[13:15]}')\n",
    "    df['day'] = df['datetime'].apply(lambda x: x.split(' ')[0])\n",
    "#     df['minutes'] = df['datetime'].apply(lambda x: int(x.split(' ')[1][:2])*60+int(x.split(' ')[1][3:5]))\n",
    "    print(len(df), len(data))\n",
    "\n",
    "    df['file'] = file.filename\n",
    "    data.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1178178 entries, 0 to 1178177\n",
      "Data columns (total 8 columns):\n",
      "datetime    1178178 non-null object\n",
      "Open        1178178 non-null float64\n",
      "High        1178178 non-null float64\n",
      "Low         1178178 non-null float64\n",
      "close       1178178 non-null float64\n",
      "Volume      1178178 non-null float64\n",
      "day         1178178 non-null object\n",
      "file        1178178 non-null object\n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 71.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>day</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-01 00:18:00</td>\n",
       "      <td>0.32408</td>\n",
       "      <td>0.32422</td>\n",
       "      <td>0.32408</td>\n",
       "      <td>0.32422</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>&lt;ZipInfo filename='ADA_1min.txt' compress_type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-01 01:04:00</td>\n",
       "      <td>0.31669</td>\n",
       "      <td>0.31669</td>\n",
       "      <td>0.31669</td>\n",
       "      <td>0.31669</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>&lt;ZipInfo filename='ADA_1min.txt' compress_type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-01 01:07:00</td>\n",
       "      <td>0.31648</td>\n",
       "      <td>0.31648</td>\n",
       "      <td>0.31648</td>\n",
       "      <td>0.31648</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>&lt;ZipInfo filename='ADA_1min.txt' compress_type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-01 01:13:00</td>\n",
       "      <td>0.31639</td>\n",
       "      <td>0.31639</td>\n",
       "      <td>0.31639</td>\n",
       "      <td>0.31639</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>&lt;ZipInfo filename='ADA_1min.txt' compress_type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-01 01:41:00</td>\n",
       "      <td>0.31540</td>\n",
       "      <td>0.31540</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>&lt;ZipInfo filename='ADA_1min.txt' compress_type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178173</th>\n",
       "      <td>2021-07-16 23:54:00</td>\n",
       "      <td>1.17230</td>\n",
       "      <td>1.17290</td>\n",
       "      <td>1.17140</td>\n",
       "      <td>1.17170</td>\n",
       "      <td>21840.483461</td>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>&lt;ZipInfo filename='ADA_1min.txt' compress_type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178174</th>\n",
       "      <td>2021-07-16 23:55:00</td>\n",
       "      <td>1.17160</td>\n",
       "      <td>1.17380</td>\n",
       "      <td>1.17160</td>\n",
       "      <td>1.17350</td>\n",
       "      <td>28098.201525</td>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>&lt;ZipInfo filename='ADA_1min.txt' compress_type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178175</th>\n",
       "      <td>2021-07-16 23:56:00</td>\n",
       "      <td>1.17360</td>\n",
       "      <td>1.17400</td>\n",
       "      <td>1.17213</td>\n",
       "      <td>1.17390</td>\n",
       "      <td>62014.284493</td>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>&lt;ZipInfo filename='ADA_1min.txt' compress_type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178176</th>\n",
       "      <td>2021-07-16 23:57:00</td>\n",
       "      <td>1.17400</td>\n",
       "      <td>1.17480</td>\n",
       "      <td>1.17309</td>\n",
       "      <td>1.17330</td>\n",
       "      <td>20986.075034</td>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>&lt;ZipInfo filename='ADA_1min.txt' compress_type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178177</th>\n",
       "      <td>2021-07-16 23:58:00</td>\n",
       "      <td>1.17330</td>\n",
       "      <td>1.17350</td>\n",
       "      <td>1.17270</td>\n",
       "      <td>1.17280</td>\n",
       "      <td>13426.283869</td>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>&lt;ZipInfo filename='ADA_1min.txt' compress_type...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1178178 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime     Open     High      Low    close  \\\n",
       "0        2018-03-01 00:18:00  0.32408  0.32422  0.32408  0.32422   \n",
       "1        2018-03-01 01:04:00  0.31669  0.31669  0.31669  0.31669   \n",
       "2        2018-03-01 01:07:00  0.31648  0.31648  0.31648  0.31648   \n",
       "3        2018-03-01 01:13:00  0.31639  0.31639  0.31639  0.31639   \n",
       "4        2018-03-01 01:41:00  0.31540  0.31540  0.31500  0.31500   \n",
       "...                      ...      ...      ...      ...      ...   \n",
       "1178173  2021-07-16 23:54:00  1.17230  1.17290  1.17140  1.17170   \n",
       "1178174  2021-07-16 23:55:00  1.17160  1.17380  1.17160  1.17350   \n",
       "1178175  2021-07-16 23:56:00  1.17360  1.17400  1.17213  1.17390   \n",
       "1178176  2021-07-16 23:57:00  1.17400  1.17480  1.17309  1.17330   \n",
       "1178177  2021-07-16 23:58:00  1.17330  1.17350  1.17270  1.17280   \n",
       "\n",
       "               Volume         day  \\\n",
       "0          600.000000  2018-03-01   \n",
       "1          300.000000  2018-03-01   \n",
       "2          400.000000  2018-03-01   \n",
       "3         7000.000000  2018-03-01   \n",
       "4          600.000000  2018-03-01   \n",
       "...               ...         ...   \n",
       "1178173  21840.483461  2021-07-16   \n",
       "1178174  28098.201525  2021-07-16   \n",
       "1178175  62014.284493  2021-07-16   \n",
       "1178176  20986.075034  2021-07-16   \n",
       "1178177  13426.283869  2021-07-16   \n",
       "\n",
       "                                                      file  \n",
       "0        <ZipInfo filename='ADA_1min.txt' compress_type...  \n",
       "1        <ZipInfo filename='ADA_1min.txt' compress_type...  \n",
       "2        <ZipInfo filename='ADA_1min.txt' compress_type...  \n",
       "3        <ZipInfo filename='ADA_1min.txt' compress_type...  \n",
       "4        <ZipInfo filename='ADA_1min.txt' compress_type...  \n",
       "...                                                    ...  \n",
       "1178173  <ZipInfo filename='ADA_1min.txt' compress_type...  \n",
       "1178174  <ZipInfo filename='ADA_1min.txt' compress_type...  \n",
       "1178175  <ZipInfo filename='ADA_1min.txt' compress_type...  \n",
       "1178176  <ZipInfo filename='ADA_1min.txt' compress_type...  \n",
       "1178177  <ZipInfo filename='ADA_1min.txt' compress_type...  \n",
       "\n",
       "[1178178 rows x 8 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3fPgwmaNFTib"
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                                                                                                   | 1/1233 [00:00<03:02,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADAUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1233/1233 [02:37<00:00,  7.84it/s]\n",
      "  0%|▏                                                                                                                                                                                                   | 1/1285 [00:00<02:08, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1285/1285 [01:11<00:00, 17.97it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1320 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCHUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1320/1320 [03:49<00:00,  5.76it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1441 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNTUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1441/1441 [03:14<00:00,  7.39it/s]\n",
      "  0%|                                                                                                                                                                                                             | 0/958 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BSVUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 958/958 [02:27<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTCUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3021/3021 [07:32<00:00,  6.68it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1353 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTGUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1353/1353 [03:27<00:00,  6.53it/s]\n",
      "  1%|█▏                                                                                                                                                                                                  | 7/1135 [00:00<00:17, 65.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVCUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1135/1135 [00:39<00:00, 28.77it/s]\n",
      "  0%|▍                                                                                                                                                                                                   | 3/1196 [00:00<00:41, 28.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAIUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1196/1196 [01:30<00:00, 13.22it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1537 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DASHUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1537/1537 [04:01<00:00,  6.37it/s]\n",
      "  4%|███████▍                                                                                                                                                                                           | 26/685 [00:00<00:02, 254.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCRUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 685/685 [00:21<00:00, 31.45it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOGEUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1506/1506 [03:35<00:00,  7.00it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1476 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOSUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1476/1476 [05:08<00:00,  4.78it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1657 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETCUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1657/1657 [04:39<00:00,  5.92it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETH-BTCUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [04:43<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETHUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1946/1946 [04:57<00:00,  6.55it/s]\n",
      "  1%|██▌                                                                                                                                                                                               | 19/1414 [00:00<00:07, 190.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1414/1414 [00:23<00:00, 59.80it/s]\n",
      "  1%|██▋                                                                                                                                                                                                 | 10/737 [00:00<00:08, 85.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 737/737 [00:06<00:00, 113.58it/s]\n",
      "  0%|▏                                                                                                                                                                                                   | 1/1347 [00:00<02:17,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICXUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:13<00:00, 10.12it/s]\n",
      "  0%|▏                                                                                                                                                                                                   | 1/1058 [00:00<01:57,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOSTUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1058/1058 [01:55<00:00,  9.16it/s]\n",
      "  1%|█▉                                                                                                                                                                                                 | 10/1006 [00:00<00:10, 98.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNCUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1006/1006 [01:27<00:00, 11.52it/s]\n",
      "  0%|                                                                                                                                                                                                             | 0/746 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINKUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 746/746 [02:20<00:00,  5.31it/s]\n",
      "  1%|█▍                                                                                                                                                                                                   | 6/797 [00:00<00:15, 52.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRCUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 797/797 [00:54<00:00, 14.60it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1261 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSKUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1261/1261 [02:07<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTCUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1657/1657 [05:05<00:00,  5.42it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1462 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIDUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1462/1462 [04:01<00:00,  6.05it/s]\n",
      "  1%|█▏                                                                                                                                                                                                  | 9/1437 [00:00<00:16, 86.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANAUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1437/1437 [00:59<00:00, 24.15it/s]\n",
      "  2%|███▊                                                                                                                                                                                              | 22/1138 [00:00<00:05, 217.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MKRUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [01:23<00:00, 13.67it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1408 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEOUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1408/1408 [04:01<00:00,  5.83it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1445 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMGUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1445/1445 [03:44<00:00,  6.43it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1129 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONTUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1129/1129 [02:24<00:00,  7.83it/s]\n",
      "  2%|████▌                                                                                                                                                                                              | 18/769 [00:00<00:04, 178.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAXUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 769/769 [00:23<00:00, 33.42it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1202 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QTUMUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1202/1202 [02:31<00:00,  7.93it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1483 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1483/1483 [02:57<00:00,  8.35it/s]\n",
      "  1%|██▋                                                                                                                                                                                                  | 8/584 [00:00<00:07, 74.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 584/584 [00:35<00:00, 16.32it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNTUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1288/1288 [00:21<00:00, 59.81it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1378 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRXUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1378/1378 [03:55<00:00,  5.85it/s]\n",
      "  0%|                                                                                                                                                                                                             | 0/958 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USTUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 958/958 [02:10<00:00,  7.36it/s]\n",
      "  1%|█▊                                                                                                                                                                                                | 11/1181 [00:00<00:10, 108.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTKUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1181/1181 [00:50<00:00, 23.36it/s]\n",
      "  0%|▉                                                                                                                                                                                                   | 5/1048 [00:00<00:22, 47.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VETUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1048/1048 [00:43<00:00, 24.03it/s]\n",
      "  1%|██▌                                                                                                                                                                                                  | 9/684 [00:00<00:08, 84.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAVESUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 684/684 [00:26<00:00, 26.03it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1463 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XEMUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1463/1463 [03:56<00:00,  6.20it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1233 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLMUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1233/1233 [03:36<00:00,  5.69it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1657 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XMRUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1657/1657 [04:38<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XRPUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1626/1626 [05:17<00:00,  5.13it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1474 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTZUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1474/1474 [04:46<00:00,  5.14it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1383 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XVGUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1383/1383 [02:29<00:00,  9.27it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1657 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZECUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1657/1657 [04:54<00:00,  5.63it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1135 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZILUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1135/1135 [02:25<00:00,  7.81it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1414 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZRXUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1414/1414 [04:45<00:00,  4.95it/s]\n"
     ]
    }
   ],
   "source": [
    "market = 'crypto'\n",
    "samples_tokenized = []\n",
    "for i in range(len(data)):\n",
    "    symbol = data[i]['file'].iloc[0].filename.split('_')[0] + 'USD'\n",
    "    print(symbol)\n",
    "    for idx, (day, group) in tqdm(enumerate(data[i].groupby('day')), total=len(data[i]['day'].unique())):\n",
    "        prompt_txt = f\"{market}_{symbol}_{day}\\n;\"\n",
    "        prompt = tokenizer.encode(prompt_txt)\n",
    "        tokens = tokenizer.encode(';'.join([f\"{row['datetime'].split(' ')[1][:5]},{row['close']}\" for idx, row in group.iterrows()]))\n",
    "        \n",
    "        token_len = (seq_len - len(prompt))\n",
    "        iters = len(tokens) // token_len\n",
    "#         leftover = len(tokens) % token_len\n",
    "#         tokens = tokens[leftover//2:-leftover//2]\n",
    "        for it in range(iters):\n",
    "            sample = prompt + tokens[it*token_len:(it+1)*token_len]\n",
    "            if len(sample) == 1024:\n",
    "                samples_tokenized.append(prompt + tokens[it*token_len:(it+1)*token_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_tokenized = np.array(samples_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514046, 1024)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all_crypto_samples', samples_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(writer, data):\n",
    "    \"\"\"\n",
    "    writes data to tfrecord file\n",
    "    \"\"\"\n",
    "    feature = {\n",
    "        \"text\": _int64_feature(data)\n",
    "    }\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(l, n):\n",
    "    # splits list/string into n size chunks\n",
    "    return [l[i:i + n] for i in range(0, len(l), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_files(files, files_per, output_dir, out_name, start_no, write_remainder=True, process_no=None):\n",
    "    # writes a list of files to .tfrecords\n",
    "    if files == None:\n",
    "        return\n",
    "    chunks = split_list(files, files_per)\n",
    "\n",
    "    if len(chunks[-1]) != files_per and not write_remainder:  # pop the last file if it's length != files per\n",
    "        remainder = chunks.pop(-1)\n",
    "    else:\n",
    "        remainder = None  # assuming files = remainder from an old chunk here\n",
    "        files_per = len(chunks[-1])\n",
    "\n",
    "    for files in chunks:\n",
    "        fp = f\"{output_dir}/{out_name}_{start_no}\"\n",
    "        if process_no is not None:\n",
    "            fp += f\"_{process_no}\"\n",
    "        fp += f\"_{files_per}\"  # add number of files in tfrecord to end of fp\n",
    "        fp += \".tfrecords\"\n",
    "        with tf.io.TFRecordWriter(fp) as writer:\n",
    "            for f in files:\n",
    "                write_to_file(writer, f)\n",
    "        start_no += 1\n",
    "    return start_no, remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tfrecords(params, write_remainder=True, write_every_n_files=1, save_checkpoints=False,\n",
    "                     resume_from_checkpoint=False, display_pbar=False):\n",
    "    files_per = 100000\n",
    "    _tfrecord_count, remainder = write_files(tokenized_files_array, files_per=files_per,\n",
    "                                                         output_dir='records', out_name='forex',\n",
    "                                                         start_no=0, process_no=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecords_mp(files, args):\n",
    "    files = split_list(files, len(files) // cpu_count())\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        pbar = tqdm(pool.imap(create_tfrecords, zip(files, repeat(args), range(len(files)))))\n",
    "        meta = {\"discarded\": 0, \"processed\": 0, \"successful\": 0}\n",
    "        for results in pbar:\n",
    "            pbar.update()\n",
    "            for k, v in results.items():\n",
    "                meta[k] += v  # update metadata\n",
    "        return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(samples_tokenized[i])==1024 for i in range(len(samples_tokenized))])/len(samples_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49541"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(max(samples_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_tokenized = np.load('all_crypto_samples.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqNpDGm_JnFk"
   },
   "source": [
    "### Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V71yg83t6Tlt"
   },
   "outputs": [],
   "source": [
    "class SongLyrics(Dataset):\n",
    "    \n",
    "    def __init__(self, data, gpt2_type=\"gpt2\", max_length=1024):\n",
    "\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
    "        self.lyrics = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.lyrics)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return torch.tensor(self.lyrics[item]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wauU2WYi92dp"
   },
   "outputs": [],
   "source": [
    "dataset = SongLyrics(samples_tokenized, gpt2_type=\"gpt2\", max_length=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124439808, 1.6094379124341003, -5.489264652483911, 0.0041308806905262984)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "get_n_params(model), np.log(5), np.log(dataset.__len__()/get_n_params(model)), dataset.__len__()/get_n_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwIRpL_5MnIY"
   },
   "source": [
    "##### Prepare training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "65ZWYy8EJl0D"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataset, model, tokenizer, batch_size_loader=32, epochs=1, \n",
    "    lr=2.5e-5, warmup_steps=200,\n",
    "    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"attempt1\",\n",
    "    test_mode=False,save_model_on_epoch=True,\n",
    "):\n",
    "    try:\n",
    "        device=torch.device(\"cuda\")\n",
    "        model = model.cuda()\n",
    "        model.train()\n",
    "\n",
    "        optimizer = AdamW(model.parameters(), lr=lr)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
    "        )\n",
    "\n",
    "        batch_size = 512//batch_size_loader\n",
    "        train_dataloader = DataLoader(dataset, batch_size=batch_size_loader, shuffle=True)\n",
    "        loss=0\n",
    "        accumulating_batch_count = 0\n",
    "        input_tensor = None\n",
    "        \n",
    "        acc = []\n",
    "        acc_sign = []\n",
    "        mae = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            print(f\"Training epoch {epoch}\")\n",
    "            print(loss)\n",
    "            pbar = tqdm(enumerate(train_dataloader), total=train_dataloader.__len__())\n",
    "            for idx, input_tensor in pbar:\n",
    "                input_tensor = input_tensor.to(device)\n",
    "                outputs = model(input_tensor, labels=input_tensor)\n",
    "                loss = outputs[0]\n",
    "                loss.backward()\n",
    "                \n",
    "#                 inp = input_tensor.cpu().detach().numpy()\n",
    "#                 logits = outputs['logits'].argmax(axis=2).cpu().detach().numpy()\n",
    "\n",
    "#                 acc.append((logits == inp).sum()/logits.size)\n",
    "#                 acc_sign.append((np.sign(logits-len(clusters)//2) == np.sign(inp-len(clusters)//2)).sum()/logits.size)\n",
    "#                 mae.append(mean_absolute_error(inp, logits)/len(clusters))\n",
    "\n",
    "                if (accumulating_batch_count % batch_size) == 0:\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    model.zero_grad()\n",
    "\n",
    "                accumulating_batch_count += 1\n",
    "                input_tensor = None\n",
    "#                 pbar.set_postfix(loss=loss.cpu().detach().numpy(), ACC=acc[-1], ACC_sign=acc_sign[-1], a_mae=mae[-1],\n",
    "#                                  lr=scheduler.get_last_lr()[0])\n",
    "            if save_model_on_epoch:\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
    "                )    \n",
    "    except Exception as e:\n",
    "        print(f'{str(e)}')\n",
    "        try:\n",
    "            del model\n",
    "            del optimizer\n",
    "            del scheduler\n",
    "            del train_dataloader\n",
    "            del loss\n",
    "            del input_tensor\n",
    "            del outputs\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIXXMDBONZtR"
   },
   "source": [
    "### Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qY7dh37IvscH",
    "outputId": "521d618e-e69b-4e65-a1b5-eeef06ca4134",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                          | 0/128512 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████████████▋                                                                                                                                                                    | 14368/128512 [1:33:01<13:00:51,  2.44it/s]"
     ]
    }
   ],
   "source": [
    "#Train the model on the specific data we have\n",
    "model = train(dataset, model, tokenizer, batch_size_loader=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yov84tK8By9U"
   },
   "outputs": [],
   "source": [
    "#Rouge score\n",
    "from rouge import Rouge\n",
    "rouge=Rouge()\n",
    "\n",
    "rouge.get_scores(test_set['Generated_lyrics'], test_set['True_end_lyrics'], avg=True, ignore_empty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXbGFCpzCtaU",
    "outputId": "8f525b2d-406a-4ad4-ce76-8553da6e6af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ayyjmc4COS4",
    "outputId": "53fa2df2-6ea1-4ff0-e833-fd4eeed0cf77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4075527115657135"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using BLEU score to compare the real sentences with the generated ones\n",
    "import statistics\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "scores=[]\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "  reference = test_set['True_end_lyrics'][i]\n",
    "  candidate = test_set['Generated_lyrics'][i]\n",
    "  scores.append(sentence_bleu(reference, candidate))\n",
    "\n",
    "statistics.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "bq6bGQTWCJ8M",
    "outputId": "b0e2047d-5d8d-43ee-e399-09dbc8204f4d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>SName</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genre</th>\n",
       "      <th>True_end_lyrics</th>\n",
       "      <th>Generated_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2946</td>\n",
       "      <td>3317</td>\n",
       "      <td>Do the Clam</td>\n",
       "      <td>(Words &amp; music by Wayne - Weisman - Fuller). H...</td>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Grab your barefoot baby by the hand. Turn and ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12130</td>\n",
       "      <td>13349</td>\n",
       "      <td>Elevation</td>\n",
       "      <td>High, higher than the sun. You shoot me from a...</td>\n",
       "      <td>U2</td>\n",
       "      <td>Rock</td>\n",
       "      <td>in the sky. You make me feel like I can fly. S...</td>\n",
       "      <td>on earth.\\nI start reading monographs about J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>596</td>\n",
       "      <td>640</td>\n",
       "      <td>Professional Torturer</td>\n",
       "      <td>Infatuation. Court well meant. 'Cause I'm the ...</td>\n",
       "      <td>Alanis Morissette</td>\n",
       "      <td>Rock</td>\n",
       "      <td>I renounce my name. Professional torturer. I d...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3733</td>\n",
       "      <td>4116</td>\n",
       "      <td>I Am Yours</td>\n",
       "      <td>I am yours. However distant you may be. There ...</td>\n",
       "      <td>Eric Clapton</td>\n",
       "      <td>Rock</td>\n",
       "      <td>me. Each memory that has left its trace with m...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11961</td>\n",
       "      <td>13175</td>\n",
       "      <td>Bombs Away</td>\n",
       "      <td>The general scratches his belly and thinks. Hi...</td>\n",
       "      <td>The Police</td>\n",
       "      <td>Rock</td>\n",
       "      <td>hard and sweet. A military man would love to m...</td>\n",
       "      <td>straight red hair.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  ...                                   Generated_lyrics\n",
       "0     2946  ...                                                   \n",
       "1    12130  ...   on earth.\\nI start reading monographs about J...\n",
       "2      596  ...                                                   \n",
       "3     3733  ...                                                   \n",
       "4    11961  ...                                 straight red hair.\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finish the sentences when there is a point, remove after that\n",
    "final=[]\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "  to_remove = test_set['Generated_lyrics'][i].split('.')[-1]\n",
    "  final.append(test_set['Generated_lyrics'][i].replace(to_remove,''))\n",
    "\n",
    "test_set['Generated_lyrics'] = final\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ghFT5K8NB_WL"
   },
   "outputs": [],
   "source": [
    "#Loop to keep only generated text and add it as a new column in the dataframe\n",
    "my_generations=[]\n",
    "\n",
    "for i in range(len(generated_lyrics)):\n",
    "  a = test_set['Lyric'][i].split()[-30:] #Get the matching string we want (30 words)\n",
    "  b = ' '.join(a)\n",
    "  c = ' '.join(generated_lyrics[i]) #Get all that comes after the matching string\n",
    "  my_generations.append(c.split(b)[-1])\n",
    "\n",
    "test_set['Generated_lyrics'] = my_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xanwpp1Wy9Pr"
   },
   "outputs": [],
   "source": [
    "#Function to generate multiple sentences. Test data should be a dataframe\n",
    "def text_generation(test_data):\n",
    "  generated_lyrics = []\n",
    "  for i in range(len(test_data)):\n",
    "    x = gen_text(test_data['Lyric'][i], tokenizer, model)\n",
    "    generated_lyrics.append(x)\n",
    "  return generated_lyrics\n",
    "\n",
    "generated_lyrics = text_generation(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pe3frhYgBTJd",
    "outputId": "03b2dd4e-c88b-4cbd-a666-78a74d17da6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I feel so unsure. As I take your hand and lead to the dance floor. As the music dies, something in your eyes. Calls to mind the silver screen. And all its sad good-byes. I\\'m never gonna dance again. Guilty feet have got no rhythm. Though it\\'s easy to pretend. I know you are not a fool. Should\\'ve known better than to cheat a friend. And waste the chance that I\\'ve been given. So I\\'m never gonna dance again. The way I danced with you. Time can never mend. The careless whispers of a good friend. To the heart and mind. Ignorance is kind. There\\'s no comfort in the truth. Pain is all you\\'ll find. I\\'m never gonna dance again. Guilty feet have got no rhythm. Though it\\'s easy to pretend. I know you are not a fool. Should\\'ve known better than to cheat a friend. And waste this chance that I\\'ve been given. So I\\'m never gonna dance again. The way I danced with you. Never without your love. Tonight the music seems so loud. I wish that we could lose this crowd. Maybe it\\'s better this way. We\\'d hurt each other. with the things we\\'d want to say. We could have been so good together. We could have lived this dance forever. But now who\\'s gonna dance with me. Please stay. And I\\'m never gonna dance again. Guilty feet have got no rhythm. Though it\\'s easy to pretend. I know you\\'re not a fool. Should\\'ve known better than to cheat a friend. And waste the chance that I\\'ve been given. So I\\'m never gonna dance again. The way I danced with you. (now that you\\'re gone) Hey ok make sure.\" [giggles as he stands up]<|endoftext|>']"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate sequences\n",
    "gen_text(df['Lyric'][0],tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yj_awltDA8t-"
   },
   "outputs": [],
   "source": [
    "## Making a function that will generate text for us ##\n",
    "def gen_text(prompt_text, tokenizer, model, n_seqs=1, max_length=374):\n",
    "  # n_seqs is the number of sequences to generate\n",
    "  # max_length is the maximum length of the sequence\n",
    "  encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "  # We are encoding the text using the gpt tokenizer. The return tensors are of type \"pt\"\n",
    "  # since we are using PyTorch, not tensorflow\n",
    "  output_sequences = model.generate(\n",
    "      input_ids=encoded_prompt,\n",
    "      max_length=max_length+len(encoded_prompt), # The model has to generate something, \n",
    "      # so we add the length of the original sequence to max_length\n",
    "      temperature=1.0,\n",
    "      top_k=0,\n",
    "      top_p=0.9,\n",
    "      repetition_penalty=1.2, # To ensure that we dont get repeated phrases\n",
    "      do_sample=True,\n",
    "      num_return_sequences=n_seqs\n",
    "  ) # We feed the encoded input into the model.\n",
    "  ## Getting the output ##\n",
    "  if len(output_sequences.shape) > 2:\n",
    "    output_sequences.squeeze_() # the _ indicates that the operation will be done in-place\n",
    "  generated_sequences = []\n",
    "  for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "    generated_sequence = generated_sequence.tolist()\n",
    "    text = tokenizer.decode(generated_sequence)\n",
    "    total_sequence = (\n",
    "        prompt_text + text[len(tokenizer.decode(encoded_prompt[0], clean_up_tokenization_spaces=True, )) :]\n",
    "    )\n",
    "    generated_sequences.append(total_sequence)\n",
    "  return generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261,
     "referenced_widgets": [
      "b0b1c1e99639492d8dbee177dfa1e373",
      "00900368e9f3448e8f62f0055dfd4565",
      "0ac6ff1f0a2e45208723d3f91e3e9a72",
      "b823e3406b0c4158a7620d969f815a52",
      "c628c2f8ada24e18bd10370a1a8427ee",
      "71792893fdd7483c84aabf458f56895f",
      "67dfaeb0f79c4b63a17d1df32b525e76",
      "1c15fa3adac64d2f954557f964705872",
      "01c48061749d469aab8236ebabe588a0",
      "f58872e9939440898d58d821e2337c07",
      "497468625a604663a183e7321b562e9c",
      "88cb9858420b4d1194c75ccd26bd1ae3",
      "1fb84f42d313450bb6db78495bfb1766",
      "6891eda4859f42ef8e104c3dc5401d11",
      "7e9168ef87eb4cd4af1cb69d3c30acb7",
      "3442fb9bf6ad46609ca9eec2fb58d87f",
      "7767f479ee3546fe8dfbcb83cfb5ea64",
      "da3052076d3443838eec59c2399c328e",
      "0156547057924f5fa2e238e0dcf03dda",
      "a5d4ffdf30a440a6a9f0172b093b0235",
      "d68e80eba3eb4a1aae79dc59e38e4389",
      "25f152f41e7f4c94a6e451ab366cc2ea",
      "e5f6f51ab412465d8ee4b0a4c8ecc55d",
      "e23aee46669743e4ba6aecbd28198f71",
      "f406148013e942769df818d3ec373d29",
      "0ffcf36a0aaa47de9928b7a02e1309c6",
      "44600666e96648feb423e8d35360a430",
      "dc043f17258a4d93bd92a0804adf23fc",
      "a8530dd74d8540e3a9ad48623cf336ae",
      "948b1bcee6a248bd98d246f41e08a19d",
      "f3a9d9169d3347f9b3a40dbcc6512c4e",
      "99db0d93939b4ecaa50df5317b80172e",
      "3e78ecdeb3664837a41a6e259c66cb32",
      "770e91cd3a634c6db1042babe4b3a755",
      "d5c95a04e19c4c5c9b73ba5060a5f7c2",
      "308dc3b23fbf4d3396f52d530684759b",
      "cdbe30522f5b4bac93772a2490e16167",
      "52890b2f3b154a6ea93b5d95b07bb952",
      "5b41721d287f4838aba338d2a38eea01",
      "4246abb63e034703935dfc57ab72ecec"
     ]
    },
    "id": "CEERhAir_yC4",
    "outputId": "4f35f2e7-4123-4335-e05c-088b71a7fc62"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b1c1e99639492d8dbee177dfa1e373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c48061749d469aab8236ebabe588a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7767f479ee3546fe8dfbcb83cfb5ea64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f406148013e942769df818d3ec373d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e78ecdeb3664837a41a6e259c66cb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = transformers.GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2AngZ1O_t5l"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwqC3uW89CCt"
   },
   "source": [
    "# GPT2 without any fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UW22zttwk4_E",
    "outputId": "2bb3a102-d6d6-4a79-db9b-3c362e3b8783"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.33620873608456614,\n",
       "  'p': 0.3805105543072668,\n",
       "  'r': 0.33900000000000013},\n",
       " 'rouge-2': {'f': 0.24573902727265526,\n",
       "  'p': 0.280178576490597,\n",
       "  'r': 0.252700228832952},\n",
       " 'rouge-l': {'f': 0.3756182538370741,\n",
       "  'p': 0.40754447860807824,\n",
       "  'r': 0.39803790370276443}}"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rouge score\n",
    "from rouge import Rouge\n",
    "rouge=Rouge()\n",
    "\n",
    "rouge.get_scores(test_set['Generated_lyrics'], test_set['True_end_lyrics'], avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEfAjgyyFnMl",
    "outputId": "469cc208-2eae-443c-f4bb-9a54dd43153d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6848624352005677"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using BLEU score to compare the real sentences with the generated ones\n",
    "import statistics\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "scores=[]\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "  reference = test_set['True_end_lyrics'][i]\n",
    "  candidate = test_set['Generated_lyrics'][i]\n",
    "  scores.append(sentence_bleu(reference, candidate))\n",
    "\n",
    "statistics.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obMubE_dPJnV"
   },
   "source": [
    "### Analyze performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8_SSPBLkq54G",
    "outputId": "e122c32c-b6e5-4331-fe9d-f57eb5e23ec1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"the. Woman without pride x 5. You don't see things like I do. You don't see things. Like I do.\""
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['True_end_lyrics'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_nd84NvRqoqU",
    "outputId": "d27bf97b-bf43-42a2-ecdb-76ad3a21f34c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" in that. Yes we've heard the great thing. I know what you've heard. You told me we've been promised so much.\""
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Generated_lyrics'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "HH53eDl6tnyf",
    "outputId": "4cc53049-fdb3-41cf-b73f-2ccfe37e7ff7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SName</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genre</th>\n",
       "      <th>True_end_lyrics</th>\n",
       "      <th>Generated_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2834</td>\n",
       "      <td>Don't Bring Me Down</td>\n",
       "      <td>Hm hm hm. Hm hm hm. I'm on my own, nowhere to ...</td>\n",
       "      <td>David Bowie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>me down. Until then I'll settle down. Say I'll...</td>\n",
       "      <td>me down. I want to see your face. I want to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6725</td>\n",
       "      <td>Flight</td>\n",
       "      <td>I've lost my balance. I fell from the trapeze....</td>\n",
       "      <td>Lifehouse</td>\n",
       "      <td>Rock</td>\n",
       "      <td>more falling). (No more striving). Only flying...</td>\n",
       "      <td>more falling). No more striving. No more hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7233</td>\n",
       "      <td>Black And Gold</td>\n",
       "      <td>If the fish swam out of the ocean. and grew le...</td>\n",
       "      <td>Lulu Santos</td>\n",
       "      <td>Rock</td>\n",
       "      <td>matter. 'cause if you're not really here. then...</td>\n",
       "      <td>magic words. 'cause if you're not real here. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2525</td>\n",
       "      <td>Hear My Train A Comin</td>\n",
       "      <td>\"YEAH, I SEE WE GOT A FEW FRIENDS LAYIN' ROUND...</td>\n",
       "      <td>Cássia Eller</td>\n",
       "      <td>Rock</td>\n",
       "      <td>YOU VERY MUCH THANK YOU VERY MUCH. THANX A LOT...</td>\n",
       "      <td>S TO YOU. YES, YES, YES. YES. YES, YES.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1778</td>\n",
       "      <td>The Hills Of Mexico</td>\n",
       "      <td>'Twas in the town of griffin. In the year of s...</td>\n",
       "      <td>Bob Dylan</td>\n",
       "      <td>Rock</td>\n",
       "      <td>the cattle run. I tread towards the hiding pla...</td>\n",
       "      <td>a horrid start. Struck my wagon, but couldn't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  ...                                   Generated_lyrics\n",
       "0   2834  ...   me down. I want to see your face. I want to s...\n",
       "1   6725  ...   more falling). No more striving. No more hear...\n",
       "2   7233  ...   magic words. 'cause if you're not real here. ...\n",
       "3   2525  ...            S TO YOU. YES, YES, YES. YES. YES, YES.\n",
       "4   1778  ...   a horrid start. Struck my wagon, but couldn't...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finish the sentences when there is a point, remove after that\n",
    "final=[]\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "  to_remove = test_set['Generated_lyrics'][i].split('.')[-1]\n",
    "  final.append(test_set['Generated_lyrics'][i].replace(to_remove,''))\n",
    "\n",
    "test_set['Generated_lyrics'] = final\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJY4jjNGGHVk"
   },
   "outputs": [],
   "source": [
    "#Loop to keep only generated text and add it as a new column in the dataframe\n",
    "my_generations=[]\n",
    "\n",
    "for i in range(len(generated_lyrics)):\n",
    "  a = test_set['Lyric'][i].split()[-30:] #Get the matching string we want (30 words)\n",
    "  b = ' '.join(a)\n",
    "  c = ' '.join(generated_lyrics[i]) #Get all that comes after the matching string\n",
    "  my_generations.append(c.split(b)[-1])\n",
    "\n",
    "test_set['Generated_lyrics'] = my_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OR4XumaWMx9d"
   },
   "outputs": [],
   "source": [
    "generated_lyrics = text_generation(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5usWIXOKKxij"
   },
   "outputs": [],
   "source": [
    "#Function to generate multiple sentences. Test data should be a dataframe\n",
    "def text_generation(test_data):\n",
    "  generated_lyrics = []\n",
    "  for i in range(len(test_data)):\n",
    "    x = generate(model.to('cpu'), tokenizer, test_data['Lyric'][i], entry_count=1)\n",
    "    generated_lyrics.append(x)\n",
    "  return generated_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQUN1Da2JluS"
   },
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt,\n",
    "    entry_count=10,\n",
    "    entry_length=30, #maximum number of words\n",
    "    top_p=0.8,\n",
    "    temperature=1.,\n",
    "):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    generated_num = 0\n",
    "    generated_list = []\n",
    "\n",
    "    filter_value = -float(\"Inf\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for entry_idx in trange(entry_count):\n",
    "\n",
    "            entry_finished = False\n",
    "\n",
    "            generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "\n",
    "            for i in range(entry_length):\n",
    "                outputs = model(generated, labels=generated)\n",
    "                loss, logits = outputs[:2]\n",
    "                logits = logits[:, -1, :] / (temperature if temperature > 0 else 1.0)\n",
    "\n",
    "                sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "                cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "                sorted_indices_to_remove = cumulative_probs > top_p\n",
    "                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[\n",
    "                    ..., :-1\n",
    "                ].clone()\n",
    "                sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "                logits[:, indices_to_remove] = filter_value\n",
    "\n",
    "                next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n",
    "                generated = torch.cat((generated, next_token), dim=1)\n",
    "\n",
    "                if next_token in tokenizer.encode(\"<|endoftext|>\"):\n",
    "                    entry_finished = True\n",
    "\n",
    "                if entry_finished:\n",
    "\n",
    "                    generated_num = generated_num + 1\n",
    "\n",
    "                    output_list = list(generated.squeeze().numpy())\n",
    "                    output_text = tokenizer.decode(output_list)\n",
    "                    generated_list.append(output_text)\n",
    "                    break\n",
    "            \n",
    "            if not entry_finished:\n",
    "              output_list = list(generated.squeeze().numpy())\n",
    "              output_text = f\"{tokenizer.decode(output_list)}<|endoftext|>\" \n",
    "              generated_list.append(output_text)\n",
    "                \n",
    "    return generated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GI3VOzbVUN7v"
   },
   "outputs": [],
   "source": [
    "#Load the model to use it\n",
    "model = torch.load('/content/drive/MyDrive/Google colabs/model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BlNPVfXPNQf"
   },
   "source": [
    "###### Text generation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "gvk9JcukKKq1"
   },
   "source": [
    "#### Save the model to a pkl or something so it can be reused later on\n",
    "torch.save(model, 'model_crypto.pt')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GPT2_final",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
